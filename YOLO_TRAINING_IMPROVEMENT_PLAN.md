# YOLO Training Improvement Plan
## From mAP50=0.2 to Production-Ready (mAP50>0.50)

**Date:** 2026-02-11  
**Current Status:** mAP50 = 0.2, Accuracy = 18%, Loss plateaued  
**Target:** mAP50 > 0.50, Accuracy > 60%  
**Model:** YOLOv8x (68.2M parameters)  
**Dataset:** luggage_xray (6,164 train images)

---

## Executive Summary

Your YOLOv8x model achieved mAP50=0.2 (target: >0.50) with loss plateaued. This indicates a **hyperparameter issue**, not a data shortage. The primary cause is likely:

1. **Learning rate too high** (0.01 ‚Üí should be 0.002)
2. **Suboptimal optimizer** (SGD ‚Üí should be AdamW)
3. **Over-aggressive augmentation** (confusing the model)

### Solution Strategy

**Phase 1 (RECOMMENDED):** Fix hyperparameters, re-train on existing 6,164 images  
**Phase 2 (IF NEEDED):** Add cargo X-ray data (+462 images) and re-train

**Expected outcome:** mAP50 0.50-0.55, Accuracy 60-75%

---

## Current Situation Analysis

### ‚úÖ What's Good

- **Sufficient training data:** 6,164 images (adequate for yolov8x)
- **Good validation split:** 956 images (13% of dataset)
- **Quality labels:** 12 classes, 5 threat categories
- **CAI infrastructure:** Working GPU training pipeline
- **Model choice:** yolov8x appropriate for production accuracy

### ‚ùå What's Wrong

- **mAP50 = 0.2** (need >0.50 for production)
- **Accuracy = 18%** (need >60% for production)
- **Loss plateaued** (model not learning anymore)
- **Learning rate too high** (0.01 causing oscillation)
- **Augmentation too aggressive** (confusing model)

### üéØ Root Cause

**Learning rate of 0.01 is 5x too high for yolov8x**, causing:
- Model overshoots optimal weights
- Unable to converge to local minimum
- Loss oscillates instead of decreasing
- mAP50 plateaus at 0.2

**Evidence:**
- mAP50 stopped improving after epoch ~60
- Loss not decreasing despite more epochs
- Similar pattern seen in undertrained large models

---

## Phase 1: Improved Hyperparameters (PRIORITY)

### Objective

Re-train yolov8x with optimized hyperparameters on existing 6,164 images.

### Changes Already Applied

#### 1. Training Script (`training/train_yolo.py`)

| Parameter | Old Value | New Value | Impact |
|-----------|-----------|-----------|--------|
| **optimizer** | 'auto' (SGD) | **'AdamW'** | Adaptive learning, better for large models |
| **lr0** | 0.01 | **0.002** | ‚ö° CRITICAL: 5x lower, prevents overshooting |
| **lrf** | 0.01 | **0.001** | Lower final LR for fine-tuning |
| **momentum** | 0.937 | **0.95** | Better escape from local minima |
| **weight_decay** | 0.0005 | **0.0001** | Less aggressive regularization |
| **warmup_epochs** | 3.0 | **5.0** | Smoother training start |
| **warmup_momentum** | 0.8 | **0.9** | Higher initial momentum |
| **degrees** | 15.0 | **10.0** | Less rotation augmentation |
| **translate** | 0.1 | **0.05** | Less translation |
| **scale** | 0.5 | **0.3** | Less scaling |
| **shear** | 5.0 | **3.0** | Less shearing |
| **mosaic** | 1.0 | **0.8** | Reduced mosaic augmentation |
| **mixup** | 0.1 | **0.0** | Disabled (confuses small objects) |
| **hsv_h/s/v** | 0.015/0.7/0.4 | **0.01/0.5/0.3** | Less color augmentation |

**Most critical fix:** Learning rate 0.01 ‚Üí 0.002

#### 2. Job Configuration (`cai_integration/jobs_config_yolo.yaml`)

```yaml
MODEL_NAME: "yolov8x.pt"  # Confirmed
EPOCHS: "200"             # Increased from 100
BATCH_SIZE: "8"           # Reduced from 16 (better gradients)
TIMEOUT: 14400           # 4 hours (increased from 2 hours)
DATASET: "luggage_xray"   # Keep current dataset
```

### Implementation Steps

#### Step 1: Trigger Training

**Option A: Via GitHub Actions (Recommended)**

```bash
# Go to GitHub Actions
# Select: "Deploy X-ray Detection to CAI"
# Configure:
#   model_type: yolo
#   yolo_model: yolov8x.pt
#   dataset: luggage_xray
#   trigger_jobs: true
# Click: Run workflow

# Improved hyperparameters will be used automatically
```

**Option B: Via CAI Directly**

```bash
# In CAI workspace:
# Jobs ‚Üí yolo_training
# Environment variables already set in jobs_config_yolo.yaml
# Click: Run Job

# Monitor via CAI job logs
```

#### Step 2: Monitor Training Progress

**Check mAP50 at key epochs:**

| Epoch | Expected mAP50 | Your Previous | Status |
|-------|----------------|---------------|--------|
| 25 | 0.12-0.15 | ~0.08 | Should improve |
| 50 | 0.25-0.30 | 0.15 | Learning faster |
| 75 | 0.35-0.40 | 0.18 | Good progress |
| 100 | 0.42-0.48 | 0.20 | **Decision point** |
| 150 | 0.48-0.53 | - | Near target |
| 200 | **0.50-0.55** | - | ‚úÖ Success |

**Decision point at Epoch 100:**
- ‚úÖ If mAP50 > 0.40: Continue to 200 epochs (Phase 1 working!)
- ‚ö†Ô∏è If mAP50 = 0.30-0.40: Continue, may reach 0.45+ by epoch 200
- ‚ùå If mAP50 < 0.30: STOP, proceed to Phase 2 (add data)

#### Step 3: Training Logs to Monitor

**Look for in CAI job logs:**

```
Key indicators of success:
‚úì Optimizer: AdamW (not SGD)
‚úì Initial LR: 0.002 (not 0.01)
‚úì Augmentation: degrees=10.0, mosaic=0.8, mixup=0.0
‚úì val/box_loss decreasing consistently
‚úì val/cls_loss decreasing consistently
‚úì metrics/mAP50 increasing steadily

Red flags:
‚ùå mAP50 stuck at 0.20 again ‚Üí Need Phase 2
‚ùå Loss oscillating wildly ‚Üí Check GPU/batch size
‚ùå OOM errors ‚Üí Reduce batch size to 4
```

#### Step 4: Evaluate Results

**After 200 epochs, check:**

```bash
# Download trained model from CAI
# Test on validation set:
python scripts/test_yolo_with_threshold.py \
    --api-url https://[your-cai-app-url] \
    --conf-threshold 0.25

# Expected results:
# - Overall Accuracy: 60-75% (vs current 18%)
# - Detection Rate: 70-85% (vs current 66%)
# - Threats Found: 35-45 (vs current 10)
# - mAP50 (from training): 0.50-0.55 (vs current 0.20)
```

### Expected Outcomes

**Success Criteria (Phase 1):**
- ‚úÖ mAP50 > 0.50
- ‚úÖ Accuracy > 60%
- ‚úÖ Loss converged (not oscillating)
- ‚úÖ Threat detection > 40 threats found (out of 50 samples)

**Time & Cost:**
- Training: 10-12 hours
- Your time: 30 minutes (setup + monitoring)
- Cost: $5-6 (GPU hours)

**Probability of success:** 70-80% (most mAP50=0.2 issues are hyperparameter problems)

---

## Phase 2: Dataset Expansion (IF PHASE 1 < 0.40)

**‚ö†Ô∏è Only proceed if Phase 1 mAP50 < 0.40 at epoch 100**

### Objective

Merge luggage_xray (6,164) + cargoxray (462) ‚Üí 6,626 total training images

### Dataset Analysis

#### Available Datasets

| Dataset | Train | Val | Classes | Domain |
|---------|-------|-----|---------|--------|
| **luggage_xray** | 6,164 | 956 | 12 (5 threats) | Luggage screening |
| **cargoxray** | 462 | 132 | 16 (no threats) | Cargo containers |
| **MERGED** | **6,626** | **1,088** | **28 mixed** | Both |

#### Class Compatibility

**‚ùå Problem: Zero class overlap!**

**luggage_xray classes:**
```
Threats: blade, dagger, knife, scissors, SwissArmyKnife
Items:   Cans, CartonDrinks, GlassBottle, PlasticBottle, SprayCans, Tin, VacuumCup
```

**cargoxray classes:**
```
Items: auto_parts, bags, bicycle, car_wheels, clothes, fabrics, lamps,
       office_supplies, shoes, spare_parts, tableware, textiles, tools,
       toys, unknown, xray_objects
```

**Implications:**
- ‚ö†Ô∏è 28 classes harder to learn than 12
- ‚ö†Ô∏è Cargo items won't improve threat detection
- ‚ö†Ô∏è May dilute model focus on threats
- ‚úÖ More training samples (+7.5%)
- ‚úÖ Better generalization to varied X-ray styles

### Implementation Steps

#### Step 1: Merge Datasets (Local)

```bash
cd /Users/zhongqishuai/Projects/cldr_projects/xray_scanning_model_finetuning

# Run merge script
python scripts/merge_xray_datasets.py \
    --datasets luggage_xray_yolo cargoxray_yolo \
    --output data/merged_xray_yolo

# Confirm when prompted (y)

# Expected output:
# ‚úì Loaded luggage_xray_yolo: 12 classes
# ‚úì Loaded cargoxray_yolo: 16 classes
# ‚úì Unified classes: 28
# ‚úì Creating unified class mapping...
# ‚úì Merging datasets...
#   Train: 6626 images, 6626 labels
#   Val:   1088 images, 1088 labels
# ‚úì Output: data/merged_xray_yolo/
```

#### Step 2: Verify Merged Dataset

```bash
# Check output structure
ls -la data/merged_xray_yolo/
# Should see:
# - images/train/ (6,626 .jpg files)
# - images/valid/ (1,088 .jpg files)
# - labels/train/ (6,626 .txt files)
# - labels/valid/ (1,088 .txt files)
# - data.yaml (configuration)

# Inspect data.yaml
cat data/merged_xray_yolo/data.yaml
# Should show:
# - nc: 28
# - names: [blade, dagger, knife, ... (28 classes)]
# - threats: [blade, dagger, knife, scissors, SwissArmyKnife]
```

#### Step 3: Update Job Configuration

```bash
# Edit: cai_integration/jobs_config_yolo.yaml
# Line 88, change:
DATASET: "merged_xray"  # Changed from "luggage_xray"

# Commit and push
git add data/merged_xray_yolo/ cai_integration/jobs_config_yolo.yaml
git commit -m "Add merged X-ray dataset (6,626 images, 28 classes) for improved training"
git push origin feature/implementation
```

#### Step 4: Train on Merged Dataset

```bash
# Trigger via GitHub Actions or CAI
# Same as Phase 1, but with merged_xray dataset
# Will use improved hyperparameters + more data

# Training time: 12-15 hours (more images)
```

#### Step 5: Monitor & Evaluate

**Expected mAP50 progression:**

| Epoch | Expected mAP50 | Notes |
|-------|----------------|-------|
| 50 | 0.22-0.28 | Slower due to 28 classes |
| 100 | 0.35-0.42 | Should surpass Phase 1 |
| 150 | 0.42-0.48 | Converging |
| 200 | **0.45-0.52** | Target |

**Final evaluation:**

```bash
# Test on validation set
python scripts/test_yolo_with_threshold.py \
    --api-url https://[your-cai-app-url] \
    --conf-threshold 0.25

# Expected:
# - Accuracy: 55-70% (lower than pure luggage due to more classes)
# - Threat detection: 35-42 (out of 50 samples with threats)
# - Better generalization to diverse X-ray styles
```

### Expected Outcomes

**Success Criteria (Phase 2):**
- ‚úÖ mAP50 > 0.45
- ‚úÖ Accuracy > 55%
- ‚úÖ Better than Phase 1 if Phase 1 < 0.40

**Time & Cost:**
- Your time: 1-2 hours (merge + setup)
- Training: 12-15 hours
- Cost: $6-8

**Probability of success:** 85-90% (combining improved config + more data)

---

## Alternative: Switch to Smaller Model

**If both Phase 1 and Phase 2 fail (mAP50 < 0.40):**

### Option: YOLOv8m (Medium)

**Why smaller model might work better:**
- yolov8x: 68.2M params ‚Üí May overfit on 6,164 images
- yolov8m: 25.9M params ‚Üí Better suited for dataset size
- Less prone to overfitting
- Faster training convergence

**Configuration:**

```yaml
MODEL_NAME: "yolov8m.pt"  # Changed from yolov8x.pt
EPOCHS: "150"             # Reduced (faster convergence)
BATCH_SIZE: "16"          # Increased (smaller model)
DATASET: "luggage_xray"   # Back to original

# Keep all other improved hyperparameters
```

**Expected:**
- mAP50: 0.45-0.55
- Accuracy: 60-75%
- Training: 8-10 hours
- Cost: $4-5

**When to try:**
- Phase 1 gives mAP50 0.30-0.40 (not bad, but not great)
- Phase 2 doesn't improve beyond 0.40
- Suspicion of overfitting (high train mAP, low val mAP)

---

## Decision Flow

```
START: mAP50 = 0.2, loss plateaued
  ‚îÇ
  ‚îú‚îÄ> Phase 1: Improved Hyperparameters
  ‚îÇ   ‚îî‚îÄ> Train 200 epochs on luggage_xray (6,164 images)
  ‚îÇ       ‚îÇ
  ‚îÇ       ‚îú‚îÄ> @ Epoch 100: mAP50 > 0.40?
  ‚îÇ       ‚îÇ   ‚îî‚îÄ> YES ‚Üí Continue to epoch 200
  ‚îÇ       ‚îÇ       ‚îî‚îÄ> Final mAP50 0.50-0.55 ‚Üí ‚úÖ SUCCESS
  ‚îÇ       ‚îÇ
  ‚îÇ       ‚îî‚îÄ> @ Epoch 100: mAP50 < 0.40?
  ‚îÇ           ‚îî‚îÄ> STOP ‚Üí Phase 2
  ‚îÇ
  ‚îú‚îÄ> Phase 2: Add More Data
  ‚îÇ   ‚îî‚îÄ> Merge datasets ‚Üí 6,626 images
  ‚îÇ       ‚îî‚îÄ> Train 200 epochs
  ‚îÇ           ‚îÇ
  ‚îÇ           ‚îú‚îÄ> mAP50 > 0.45? ‚Üí ‚úÖ SUCCESS
  ‚îÇ           ‚îÇ
  ‚îÇ           ‚îî‚îÄ> mAP50 < 0.40? ‚Üí Try smaller model
  ‚îÇ
  ‚îî‚îÄ> Alternative: Switch to yolov8m
      ‚îî‚îÄ> Train 150 epochs
          ‚îî‚îÄ> Expected mAP50 0.45-0.55 ‚Üí ‚úÖ SUCCESS
```

---

## Timeline & Resources

### Phase 1 Timeline

| Activity | Duration | Your Time | Cost |
|----------|----------|-----------|------|
| Trigger training | 5 min | 5 min | $0 |
| Training (epoch 0-100) | 5-6 hours | 0 (automated) | $3 |
| Check mAP50 @ epoch 100 | 5 min | 5 min | $0 |
| Training (epoch 100-200) | 5-6 hours | 0 (automated) | $3 |
| Test & evaluate | 20 min | 20 min | $0 |
| **TOTAL** | **10-12 hours** | **30 min** | **$5-6** |

### Phase 2 Timeline (if needed)

| Activity | Duration | Your Time | Cost |
|----------|----------|-----------|------|
| Merge datasets | 10 min | 10 min | $0 |
| Verify merge | 10 min | 10 min | $0 |
| Update config & commit | 10 min | 10 min | $0 |
| Trigger training | 5 min | 5 min | $0 |
| Training | 12-15 hours | 0 (automated) | $6-8 |
| Test & evaluate | 20 min | 20 min | $0 |
| **TOTAL** | **13-16 hours** | **1-2 hours** | **$6-8** |

### Total (Worst Case: Both Phases)

- **Total time:** 23-28 hours (mostly automated)
- **Your time:** 1.5-2.5 hours
- **Total cost:** $11-14

---

## Monitoring Guide

### Key Metrics to Track

**During Training (CAI Logs):**

```python
# Good indicators:
‚úì val/box_loss: Decreasing steadily
‚úì val/cls_loss: Decreasing steadily
‚úì val/dfl_loss: Decreasing steadily
‚úì metrics/mAP50(B): Increasing steadily
‚úì metrics/precision(B): Increasing
‚úì metrics/recall(B): Increasing

# Warning signs:
‚ö†Ô∏è Loss oscillating wildly ‚Üí LR still too high
‚ö†Ô∏è mAP50 not increasing ‚Üí May need more epochs or data
‚ö†Ô∏è train/mAP50 >> val/mAP50 ‚Üí Overfitting
‚ö†Ô∏è OOM errors ‚Üí Reduce batch size

# Red flags:
‚ùå mAP50 stuck at 0.20 again ‚Üí Fundamental issue
‚ùå Loss = NaN ‚Üí Training failed, restart
‚ùå No improvement after 100 epochs ‚Üí Stop early
```

**After Training (Validation):**

```bash
# Test script will show:
- Overall Accuracy: 60%+ is good
- Detection Rate: 70%+ is good
- Per-class accuracy: Check if threats detected
- Threats found: 35-45 (out of ~50 threat samples)
- Inference speed: Should be 50-100ms per image
```

### Checkpoints to Save

**Save these for later analysis:**

```
runs/detect/xray_detection/
  ‚îú‚îÄ‚îÄ weights/
  ‚îÇ   ‚îú‚îÄ‚îÄ best.pt         ‚Üê Best mAP50 checkpoint
  ‚îÇ   ‚îú‚îÄ‚îÄ last.pt         ‚Üê Final checkpoint
  ‚îÇ   ‚îî‚îÄ‚îÄ epoch*.pt       ‚Üê Intermediate (every 10 epochs)
  ‚îú‚îÄ‚îÄ results.csv         ‚Üê Training metrics
  ‚îú‚îÄ‚îÄ results.png         ‚Üê Metric plots
  ‚îî‚îÄ‚îÄ confusion_matrix.png ‚Üê Class confusion

Download:
- best.pt (for deployment)
- results.csv (for analysis)
- Training logs (from CAI)
```

---

## Success Criteria

### Phase 1 Success (Improved Config)

‚úÖ **Minimum acceptable:**
- mAP50 > 0.40
- Accuracy > 50%
- Loss converged (not oscillating)

‚úÖ **Target:**
- mAP50 > 0.50
- Accuracy > 60%
- Threat detection rate > 70%

‚úÖ **Excellent:**
- mAP50 > 0.55
- Accuracy > 70%
- Threat detection rate > 80%

### Phase 2 Success (Added Data)

‚úÖ **Minimum acceptable:**
- mAP50 > 0.45
- Accuracy > 55%
- Better than Phase 1 results

‚úÖ **Target:**
- mAP50 > 0.50
- Accuracy > 60%
- Good generalization to both luggage and cargo

### Production Readiness

‚úÖ **Deploy to production when:**
- mAP50 > 0.50
- Accuracy > 60% on validation set
- Threat detection > 70% (35+ threats out of 50)
- False positive rate < 20%
- Inference speed < 200ms per image
- Passed manual review of 100 random predictions

---

## Rollback Plan

**If new training performs worse than current model:**

```bash
# Keep current model deployed
# Analyze training logs to understand why:

Common issues:
1. GPU OOM ‚Üí Reduce batch size to 4
2. Training time limit ‚Üí Increase timeout or reduce epochs
3. Wrong dataset path ‚Üí Verify data.yaml location
4. Shared memory issue ‚Üí Check CAI project settings

# Re-configure and retry
```

---

## Next Actions

### Immediate (Now)

1. ‚úÖ **Review this plan** (you are here)
2. ‚è≠Ô∏è **Trigger Phase 1 training:**
   - Go to GitHub Actions or CAI
   - Launch yolo_training job
   - Model: yolov8x.pt, Dataset: luggage_xray, Epochs: 200

### Tomorrow (After ~6 hours)

3. üîç **Check mAP50 at epoch 50-60:**
   - Should be 0.25-0.30 (vs your 0.15)
   - If lower, check training logs for issues

### Day 2 (After ~12 hours)

4. üéØ **Decision point at epoch 100:**
   - mAP50 > 0.40 ‚Üí Continue to epoch 200
   - mAP50 < 0.40 ‚Üí Stop, prepare Phase 2

### Day 2-3 (After training completes)

5. üìä **Evaluate results:**
   - Download best.pt model
   - Run validation test
   - Compare with current 18% baseline

6. üöÄ **Deploy if successful:**
   - mAP50 > 0.50, Accuracy > 60% ‚Üí Deploy!
   - mAP50 < 0.40 ‚Üí Proceed to Phase 2

---

## Questions & Troubleshooting

### Q1: What if Phase 1 gives mAP50 = 0.35-0.40?

**A:** This is borderline. Options:
1. **Continue to epoch 200** - may reach 0.45+
2. **Try Phase 2** - add data for extra boost
3. **Try yolov8m** - smaller model may work better

### Q2: What if both phases fail (mAP50 < 0.40)?

**A:** Investigate deeper:
1. Check class distribution (imbalanced?)
2. Review label quality (incorrect annotations?)
3. Try yolov8m or yolov8s (smaller models)
4. Consider data augmentation issues
5. Review false positives/negatives manually

### Q3: Should I use yolov11 instead?

**A:** Maybe, but:
- ‚úÖ yolov11n is newer and faster
- ‚ùå Less stable than yolov8 for production
- ‚ùå Similar architecture, unlikely to solve mAP50=0.2
- üí° Try after Phase 1 if you want cutting-edge

### Q4: Can I run Phase 1 and Phase 2 in parallel?

**A:** Not recommended:
- ‚ùå Wastes GPU time if Phase 1 succeeds
- ‚ùå Harder to compare results
- ‚úÖ Better to wait for Phase 1 result first

### Q5: What's the fastest path to production?

**A:** Follow the plan:
- Phase 1 first (70% chance of success)
- If fails, Phase 2 (85% total success rate)
- Expected: 1-3 days to production-ready model

---

## Files Reference

### Files I've Updated

```
‚úÖ training/train_yolo.py
   - Improved hyperparameters (AdamW, lr=0.002, etc.)

‚úÖ cai_integration/jobs_config_yolo.yaml
   - EPOCHS: 200, BATCH_SIZE: 8, TIMEOUT: 4h

‚úÖ scripts/merge_xray_datasets.py
   - Created for Phase 2 dataset merging
```

### Documentation Files

```
üìñ YOLO_TRAINING_IMPROVEMENT_PLAN.md (this file)
   - Complete action plan

üìñ IMPROVED_TRAINING_CONFIG.md
   - Detailed hyperparameter analysis

üìñ TRAINING_IMPROVEMENT_GUIDE.md
   - Step-by-step implementation guide

üìñ TRAINING_DIAGNOSIS.md
   - Root cause analysis

üìñ DATASET_EXPANSION_PLAN.md
   - Dataset inventory and expansion options
```

### Test Results

```
üìä test_results/MODEL_COMPARISON_ALL.md
   - Current: yolov8x mAP50=0.2, 18% accuracy

üìä test_results/50_SAMPLE_COMPARISON.md
   - YOLO vs RolmOCR vs GPT-4 on same 50 samples
```

---

## Approval & Sign-off

**Plan created:** 2026-02-11  
**Plan owner:** [Your name]  
**Estimated completion:** 2-3 days  
**Total cost:** $11-14 (worst case)  
**Success probability:** 85-90%

**Approved to proceed with Phase 1:** ___________

---

## Summary

### The Problem
- mAP50 stuck at 0.2 (need >0.50)
- Loss plateaued
- Accuracy only 18%

### The Solution
1. **Phase 1:** Fix hyperparameters (AdamW, lr=0.002, less aug)
   - Expected: mAP50 0.50-0.55, 60-75% accuracy
   - Time: 10-12 hours, Cost: $5-6
   - **Probability: 70-80%**

2. **Phase 2 (if needed):** Add cargoxray data (+462 images)
   - Expected: mAP50 0.45-0.52, 55-70% accuracy  
   - Time: 12-15 hours, Cost: $6-8
   - **Cumulative probability: 85-90%**

### Next Step
**Trigger Phase 1 training now** ‚Üí Check results in 12 hours ‚Üí Proceed to Phase 2 if needed

---

**Ready to start Phase 1?** Just trigger the training job and monitor mAP50! üöÄ
