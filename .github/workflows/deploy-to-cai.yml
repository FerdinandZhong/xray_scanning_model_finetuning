name: Deploy X-ray Detection to CAI

on:
  workflow_dispatch:
    inputs:
      model_type:
        description: 'Model architecture'
        required: true
        default: 'yolo'
        type: choice
        options:
          - yolo
          - vlm
      dataset:
        description: '[YOLO] Dataset to train on'
        required: false
        default: 'luggage_xray'
        type: choice
        options:
          - luggage_xray
          - cargoxray
          - stcray
      yolo_model:
        description: '[YOLO] Model variant (yolov8n=fastest, yolov8s=balanced, yolov8m=accurate)'
        required: false
        default: 'yolov8n.pt'
        type: string
      yolo_epochs:
        description: '[YOLO] Training epochs'
        required: false
        default: '100'
        type: string
      export_onnx:
        description: '[YOLO] Export to ONNX after training'
        required: false
        default: false
        type: boolean
      vllm_endpoint:
        description: '[VLM] External vLLM server endpoint (e.g., http://server:8000/v1) - Optional: can configure in CAI later'
        required: false
        default: ''
        type: string
      samples_per_image:
        description: '[VLM] VQA samples per image'
        required: false
        default: '3'
        type: string
      api_key:
        description: '[VLM] API key for OpenAI/Claude/authenticated vLLM (optional)'
        required: false
        default: ''
        type: string
      force_reinstall:
        description: 'Force environment reinstall'
        required: false
        default: false
        type: boolean
      trigger_jobs:
        description: 'Automatically trigger pipeline after setup'
        required: false
        default: false
        type: boolean
      deploy_api:
        description: '[YOLO] Deploy trained model as CAI Application with exposed endpoints'
        required: false
        default: true
        type: boolean
      api_subdomain:
        description: '[YOLO] Custom subdomain for API (e.g., xray-yolo-v2)'
        required: false
        default: 'xray-yolo-api'
        type: string

jobs:
  validate:
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          lfs: true  # Download Git LFS files (datasets)

      - name: Check model type configuration
        run: |
          echo "üîç Checking model type: ${{ github.event.inputs.model_type }}"
          if [ "${{ github.event.inputs.model_type }}" = "yolo" ]; then
            echo "‚úÖ Using YOLO detection model"
            echo "   Dataset: ${{ github.event.inputs.dataset }}"
            echo "   Model: ${{ github.event.inputs.yolo_model }}"
            echo "   Epochs: ${{ github.event.inputs.yolo_epochs }}"
            echo "   Export ONNX: ${{ github.event.inputs.export_onnx }}"
            if [ "${{ github.event.inputs.dataset }}" = "cargoxray" ]; then
              echo "   üöÄ CargoXray: Quick baseline (~30 min)"
            else
              echo "   üöÄ STCray: Production model (~4 hours)"
            fi
          elif [ "${{ github.event.inputs.model_type }}" = "vlm" ]; then
            echo "‚úÖ Using VLM (Vision-Language Model) approach"
            if [ -z "${{ github.event.inputs.vllm_endpoint }}" ]; then
              echo "‚ö†Ô∏è  Warning: vLLM endpoint not provided"
              echo "   Jobs will be created with placeholder endpoint"
              echo "   You must configure the endpoint in CAI before running jobs"
            else
              echo "   vLLM endpoint: ${{ github.event.inputs.vllm_endpoint }}"
            fi
          fi

      - name: Validate configuration files
        run: |
          echo "üîç Validating configuration files..."
          # Check required files exist based on model type
          if [ "${{ github.event.inputs.model_type }}" = "yolo" ]; then
            test -f cai_integration/jobs_config_yolo.yaml
          else
            test -f cai_integration/jobs_config.yaml
          fi
          test -f cai_integration/create_jobs.py
          test -f cai_integration/trigger_jobs.py
          echo "‚úÖ Configuration files validated"

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Validate YAML syntax
        run: |
          echo "üîç Validating YAML syntax..."
          pip install pyyaml
          if [ "${{ github.event.inputs.model_type }}" = "yolo" ]; then
            python -c "import yaml; yaml.safe_load(open('cai_integration/jobs_config_yolo.yaml'))"
          else
            python -c "import yaml; yaml.safe_load(open('cai_integration/jobs_config.yaml'))"
          fi
          echo "‚úÖ YAML syntax valid"

  setup-project:
    needs: validate
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      project_id: ${{ steps.setup.outputs.project_id }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          lfs: true  # Download Git LFS files (datasets)

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pyyaml

      - name: Setup CAI Project
        id: setup
        env:
          CML_HOST: ${{ secrets.CML_HOST }}
          CML_API_KEY: ${{ secrets.CML_API_KEY }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GH_PAT: ${{ secrets.GH_PAT || secrets.GITHUB_TOKEN }}
        run: |
          echo "üöÄ Setting up CAI project for X-ray VQA..."
          python cai_integration/setup_project.py
          PROJECT_ID=$(cat /tmp/project_id.txt)
          echo "project_id=$PROJECT_ID" >> $GITHUB_OUTPUT
          echo "‚úÖ Project ID: $PROJECT_ID"

      - name: Create job summary
        if: always()
        run: |
          echo "## X-ray VQA Setup: Project" >> $GITHUB_STEP_SUMMARY
          echo "**Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "**Project ID**: ${{ steps.setup.outputs.project_id }}" >> $GITHUB_STEP_SUMMARY
          echo "**Repository**: ${{ github.repository }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -z "${{ github.event.inputs.vllm_endpoint }}" ]; then
            echo "‚ö†Ô∏è **Warning**: vLLM endpoint not provided - jobs will not be triggered" >> $GITHUB_STEP_SUMMARY
          fi

  create-jobs:
    needs: setup-project
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          lfs: true  # Download Git LFS files (datasets)

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pyyaml

      - name: Update jobs config with parameters
        run: |
          echo "üìù Updating jobs config with parameters..."
          python3 << 'PYTHON_SCRIPT'
          import yaml
          
          model_type = '${{ github.event.inputs.model_type }}'
          config_file = f'cai_integration/jobs_config{"_yolo" if model_type == "yolo" else ""}.yaml'
          
          with open(config_file) as f:
              config = yaml.safe_load(f)
          
          # Update force_reinstall for all model types
          config['jobs']['setup_environment']['environment']['FORCE_REINSTALL'] = 'true' if '${{ github.event.inputs.force_reinstall }}' == 'true' else 'false'
          
          if model_type == 'yolo':
              # Configure YOLO-specific parameters
              dataset = '${{ github.event.inputs.dataset }}'
              config['jobs']['yolo_training']['environment']['MODEL_NAME'] = '${{ github.event.inputs.yolo_model }}'
              config['jobs']['yolo_training']['environment']['EPOCHS'] = '${{ github.event.inputs.yolo_epochs }}'
              config['jobs']['yolo_training']['environment']['EXPORT_ONNX'] = 'true' if '${{ github.event.inputs.export_onnx }}' == 'true' else 'false'
              config['jobs']['yolo_training']['environment']['DATASET'] = dataset
              
              # Adjust timeout and dependencies based on dataset
              # Also remove unused download jobs to avoid errors
              if dataset == 'luggage_xray':
                  # Luggage X-ray needs to be downloaded from Roboflow
                  config['jobs']['yolo_training']['timeout'] = 7200  # 2 hours
                  config['jobs']['yolo_training']['parent_job_key'] = 'download_luggage_xray'
                  # Remove unused download job
                  if 'download_dataset' in config['jobs']:
                      del config['jobs']['download_dataset']
                  print(f"‚úì Luggage X-ray: Will download from Roboflow")
              elif dataset == 'cargoxray':
                  # CargoXray is in Git LFS, no download needed
                  config['jobs']['yolo_training']['timeout'] = 3600  # 1 hour
                  config['jobs']['yolo_training']['parent_job_key'] = 'setup_environment'  # Skip download
                  # Remove both download jobs (not needed for LFS data)
                  if 'download_luggage_xray' in config['jobs']:
                      del config['jobs']['download_luggage_xray']
                  if 'download_dataset' in config['jobs']:
                      del config['jobs']['download_dataset']
                  print(f"‚úì CargoXray: Using Git LFS (no download job needed)")
              else:  # stcray
                  # STCray needs to be downloaded from HuggingFace
                  config['jobs']['yolo_training']['timeout'] = 14400  # 4 hours
                  config['jobs']['yolo_training']['parent_job_key'] = 'download_dataset'
                  config['jobs']['download_dataset']['timeout'] = 3600  # 1 hour
                  # Remove unused download job
                  if 'download_luggage_xray' in config['jobs']:
                      del config['jobs']['download_luggage_xray']
                  print(f"‚úì STCray: Will download from HuggingFace")
              
              print(f"‚úì YOLO configuration:")
              print(f"  Dataset: {dataset}")
              print(f"  Model: {config['jobs']['yolo_training']['environment']['MODEL_NAME']}")
              print(f"  Epochs: {config['jobs']['yolo_training']['environment']['EPOCHS']}")
              print(f"  Export ONNX: {config['jobs']['yolo_training']['environment']['EXPORT_ONNX']}")
              print(f"  Parent Job: {config['jobs']['yolo_training']['parent_job_key']}")
              print(f"  Timeout: {config['jobs']['yolo_training']['timeout']}s")
          else:
              # Configure VLM-specific parameters
              vllm_endpoint = '${{ github.event.inputs.vllm_endpoint }}'
              if vllm_endpoint:
                  config['jobs']['generate_vqa']['environment']['VLLM_API_BASE'] = vllm_endpoint
                  print(f"‚úì vLLM endpoint configured: {vllm_endpoint}")
              else:
                  config['jobs']['generate_vqa']['environment']['VLLM_API_BASE'] = 'CONFIGURE_IN_CAI_BEFORE_RUNNING'
                  print("‚ö† vLLM endpoint not provided - using placeholder")
              
              config['jobs']['generate_vqa']['environment']['SAMPLES_PER_IMAGE'] = '${{ github.event.inputs.samples_per_image }}'
              config['jobs']['generate_vqa']['environment']['API_KEY'] = '${{ github.event.inputs.api_key }}'
          
          with open(config_file, 'w') as f:
              yaml.dump(config, f, default_flow_style=False)
          PYTHON_SCRIPT
          echo "‚úÖ Configuration updated"

      - name: Create CAI Jobs
        env:
          CML_HOST: ${{ secrets.CML_HOST }}
          CML_API_KEY: ${{ secrets.CML_API_KEY }}
        run: |
          MODEL_TYPE="${{ github.event.inputs.model_type }}"
          if [ "$MODEL_TYPE" = "yolo" ]; then
            CONFIG_FILE="cai_integration/jobs_config_yolo.yaml"
            echo "üìã Creating YOLO detection jobs..."
          else
            CONFIG_FILE="cai_integration/jobs_config.yaml"
            echo "üìã Creating VLM training jobs..."
          fi
          
          echo "Using config: $CONFIG_FILE"
          python cai_integration/create_jobs.py \
            --project-id ${{ needs.setup-project.outputs.project_id }} \
            --config "$CONFIG_FILE"
          echo "‚úÖ Jobs created"

      - name: Create job summary
        if: always()
        run: |
          MODEL_TYPE="${{ github.event.inputs.model_type }}"
          
          echo "## X-ray Detection Setup: Jobs" >> $GITHUB_STEP_SUMMARY
          echo "**Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "**Model Type**: $MODEL_TYPE" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$MODEL_TYPE" = "yolo" ]; then
            echo "### YOLO Configuration" >> $GITHUB_STEP_SUMMARY
            echo "- **Dataset**: ${{ github.event.inputs.dataset }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Model**: ${{ github.event.inputs.yolo_model }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Epochs**: ${{ github.event.inputs.yolo_epochs }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Export ONNX**: ${{ github.event.inputs.export_onnx }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Jobs Created" >> $GITHUB_STEP_SUMMARY
            echo "1. setup_environment" >> $GITHUB_STEP_SUMMARY
            echo "2. download_dataset" >> $GITHUB_STEP_SUMMARY
            echo "3. yolo_training ‚Üê Fine-tuning job" >> $GITHUB_STEP_SUMMARY
            if [ "${{ github.event.inputs.deploy_api }}" = "true" ]; then
              echo "4. deploy_yolo_application ‚Üê API deployment job" >> $GITHUB_STEP_SUMMARY
            fi
          else
            if [ -z "${{ github.event.inputs.vllm_endpoint }}" ]; then
              echo "‚ö†Ô∏è **vLLM Endpoint**: Not provided (placeholder used)" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### Action Required" >> $GITHUB_STEP_SUMMARY
              echo "Before running the VQA generation job in CAI:" >> $GITHUB_STEP_SUMMARY
              echo "1. Go to CAI UI ‚Üí Jobs ‚Üí generate_vqa" >> $GITHUB_STEP_SUMMARY
              echo "2. Edit job environment variables" >> $GITHUB_STEP_SUMMARY
              echo "3. Set VLLM_API_BASE to your actual vLLM server endpoint" >> $GITHUB_STEP_SUMMARY
              echo "4. Then trigger the job manually" >> $GITHUB_STEP_SUMMARY
            else
              echo "‚úÖ **vLLM Endpoint**: ${{ github.event.inputs.vllm_endpoint }}" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Samples per Image**: ${{ github.event.inputs.samples_per_image }}" >> $GITHUB_STEP_SUMMARY
            echo "**API Key**: ${{ github.event.inputs.api_key && '<configured>' || '<not provided>' }}" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Force Reinstall**: ${{ github.event.inputs.force_reinstall }}" >> $GITHUB_STEP_SUMMARY
          
          if [ "$MODEL_TYPE" = "yolo" ] && [ "${{ github.event.inputs.deploy_api }}" = "true" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### API Deployment" >> $GITHUB_STEP_SUMMARY
            echo "After training completes, the model will be automatically deployed as a CAI Application:" >> $GITHUB_STEP_SUMMARY
            echo "- **Subdomain**: ${{ github.event.inputs.api_subdomain }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Endpoints**: /health, /docs, /v1/detect, /v1/chat/completions" >> $GITHUB_STEP_SUMMARY
            echo "- **Access**: https://${{ github.event.inputs.api_subdomain }}.[your-domain]" >> $GITHUB_STEP_SUMMARY
          fi

  deploy-yolo-api:
    needs: [setup-project, create-jobs, trigger-pipeline]
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: |
      always() &&
      github.event.inputs.model_type == 'yolo' &&
      github.event.inputs.deploy_api == 'true' &&
      (needs.trigger-pipeline.result == 'success' || needs.trigger-pipeline.result == 'skipped')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pyyaml

      - name: Update deployment job configuration
        env:
          CML_HOST: ${{ secrets.CML_HOST }}
          CML_API_KEY: ${{ secrets.CML_API_KEY }}
        run: |
          echo "üìù Configuring YOLO API deployment job..."
          python3 << 'PYTHON_SCRIPT'
          import yaml
          
          config_file = 'cai_integration/jobs_config_yolo.yaml'
          
          with open(config_file) as f:
              config = yaml.safe_load(f)
          
          # Update deployment job configuration
          if 'deploy_yolo_application' in config['jobs']:
              config['jobs']['deploy_yolo_application']['environment']['CAI_API_KEY'] = '${{ secrets.CML_API_KEY }}'
              config['jobs']['deploy_yolo_application']['environment']['CAI_DOMAIN'] = '${{ secrets.CML_HOST }}'
              config['jobs']['deploy_yolo_application']['environment']['APP_SUBDOMAIN'] = '${{ github.event.inputs.api_subdomain }}'
              
              # Determine MODEL_PATH and parent_job_key based on workflow context
              # If trigger_jobs=true: training happens, so auto-detect (empty string) and depend on yolo_training
              # If trigger_jobs=false: deploy pre-trained model directly, use yolo_model input and depend on setup_environment
              trigger_jobs = '${{ github.event.inputs.trigger_jobs }}' == 'true'
              yolo_model = '${{ github.event.inputs.yolo_model }}'
              
              if trigger_jobs:
                  # Auto-detect trained model after training completes
                  model_path = ""
                  model_desc = "Auto-detect from training"
                  # Keep parent_job_key as 'yolo_training' (default in config)
              else:
                  # Deploy pre-trained model directly (skip training)
                  model_path = yolo_model
                  model_desc = f"Pre-trained: {yolo_model}"
                  # Change parent_job_key to setup_environment (no training needed)
                  config['jobs']['deploy_yolo_application']['parent_job_key'] = 'setup_environment'
              
              config['jobs']['deploy_yolo_application']['environment']['MODEL_PATH'] = model_path
              
              print(f"‚úì Deployment job configured:")
              print(f"  Subdomain: ${{ github.event.inputs.api_subdomain }}")
              print(f"  Model: {model_desc}")
              print(f"  Parent: {config['jobs']['deploy_yolo_application']['parent_job_key']}")
              if trigger_jobs:
                  print(f"  API will be deployed after training completes")
              else:
                  print(f"  API will be deployed directly with pre-trained model")
          
          with open(config_file, 'w') as f:
              yaml.dump(config, f, default_flow_style=False)
          PYTHON_SCRIPT
          echo "‚úÖ Deployment configuration updated"

      - name: Enable deployment job in CAI
        env:
          CML_HOST: ${{ secrets.CML_HOST }}
          CML_API_KEY: ${{ secrets.CML_API_KEY }}
        run: |
          echo "üîÑ Updating deployment job in CAI..."
          python cai_integration/create_jobs.py \
            --project-id ${{ needs.setup-project.outputs.project_id }} \
            --config cai_integration/jobs_config_yolo.yaml
          echo "‚úÖ Deployment job updated and ready"

      - name: Create deployment summary
        if: always()
        run: |
          echo "## YOLO API Deployment Configuration" >> $GITHUB_STEP_SUMMARY
          echo "**Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Deployment Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Subdomain**: ${{ github.event.inputs.api_subdomain }}" >> $GITHUB_STEP_SUMMARY
          if [[ "${{ github.event.inputs.trigger_jobs }}" == "true" ]]; then
            echo "- **Model**: Auto-detect from training" >> $GITHUB_STEP_SUMMARY
            echo "- **Trigger**: Automatically after training completes" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **Model**: Pre-trained ${{ github.event.inputs.yolo_model }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Trigger**: Directly after environment setup" >> $GITHUB_STEP_SUMMARY
          fi
          echo "- **Startup Time**: 1-2 minutes" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Available Endpoints (after deployment)" >> $GITHUB_STEP_SUMMARY
          echo "- Health Check: \`GET https://${{ github.event.inputs.api_subdomain }}.[domain]/health\`" >> $GITHUB_STEP_SUMMARY
          echo "- API Docs: \`GET https://${{ github.event.inputs.api_subdomain }}.[domain]/docs\`" >> $GITHUB_STEP_SUMMARY
          echo "- Direct Detection: \`POST https://${{ github.event.inputs.api_subdomain }}.[domain]/v1/detect\`" >> $GITHUB_STEP_SUMMARY
          echo "- OpenAI Format: \`POST https://${{ github.event.inputs.api_subdomain }}.[domain]/v1/chat/completions\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Monitoring" >> $GITHUB_STEP_SUMMARY
          echo "1. Check job status in CAI UI: Jobs ‚Üí deploy_yolo_application" >> $GITHUB_STEP_SUMMARY
          echo "2. View application status: Applications ‚Üí xray-yolo-detection-api" >> $GITHUB_STEP_SUMMARY
          echo "3. Check application logs for any errors" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Testing the Deployed API" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`bash" >> $GITHUB_STEP_SUMMARY
          echo "# Health check" >> $GITHUB_STEP_SUMMARY
          echo "curl https://${{ github.event.inputs.api_subdomain }}.[your-domain]/health" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# Test detection" >> $GITHUB_STEP_SUMMARY
          echo "curl -X POST https://${{ github.event.inputs.api_subdomain }}.[your-domain]/v1/detect \\" >> $GITHUB_STEP_SUMMARY
          echo "  -F 'file=@image.jpg'" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

  trigger-pipeline:
    needs: [setup-project, create-jobs]
    runs-on: ubuntu-latest
    timeout-minutes: 5
    if: |
      github.event.inputs.trigger_jobs == 'true' && 
      github.event.inputs.vllm_endpoint != ''

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          lfs: true  # Download Git LFS files (datasets)

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pyyaml

      - name: Trigger Pipeline
        env:
          CML_HOST: ${{ secrets.CML_HOST }}
          CML_API_KEY: ${{ secrets.CML_API_KEY }}
        run: |
          echo "üöÄ Triggering X-ray VQA pipeline..."
          echo "Note: This only triggers the root job (setup_environment)"
          echo "Child jobs will auto-trigger via CAI dependencies"
          python cai_integration/trigger_jobs.py \
            --project-id ${{ needs.setup-project.outputs.project_id }}
          echo "‚úÖ Pipeline triggered"

      - name: Create summary
        if: always()
        run: |
          echo "## X-ray VQA Pipeline Triggered" >> $GITHUB_STEP_SUMMARY
          echo "**Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "1. Monitor job execution in CAI UI: Jobs > Job Runs" >> $GITHUB_STEP_SUMMARY
          echo "2. Pipeline will take 11-19 hours to complete" >> $GITHUB_STEP_SUMMARY
          echo "3. Check logs for any errors" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Job Execution Order" >> $GITHUB_STEP_SUMMARY
          echo "- setup_environment (triggered now)" >> $GITHUB_STEP_SUMMARY
          echo "- download_dataset (auto-triggers after setup)" >> $GITHUB_STEP_SUMMARY
          echo "- generate_vqa (auto-triggers after download)" >> $GITHUB_STEP_SUMMARY
          echo "- finetune_model (auto-triggers after VQA generation)" >> $GITHUB_STEP_SUMMARY

  skip-trigger:
    needs: [setup-project, create-jobs]
    runs-on: ubuntu-latest
    if: |
      github.event.inputs.trigger_jobs == 'true' && 
      github.event.inputs.vllm_endpoint == ''

    steps:
      - name: Warning message
        run: |
          echo "‚ö†Ô∏è Pipeline trigger skipped - vLLM endpoint not provided"
          echo ""
          echo "Jobs have been created but not triggered."
          echo "To run the pipeline:"
          echo "1. Configure vLLM_API_BASE in CAI UI"
          echo "2. Manually trigger the setup_environment job"

      - name: Create summary
        run: |
          echo "## Pipeline Trigger Skipped" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚ö†Ô∏è **Reason**: vLLM endpoint not provided" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Manual Steps Required" >> $GITHUB_STEP_SUMMARY
          echo "1. Go to CAI UI ‚Üí Jobs ‚Üí generate_vqa" >> $GITHUB_STEP_SUMMARY
          echo "2. Edit environment variables" >> $GITHUB_STEP_SUMMARY
          echo "3. Set VLLM_API_BASE to your vLLM server endpoint" >> $GITHUB_STEP_SUMMARY
          echo "4. Go to Jobs ‚Üí setup_environment" >> $GITHUB_STEP_SUMMARY
          echo "5. Click 'Run' to start the pipeline" >> $GITHUB_STEP_SUMMARY
